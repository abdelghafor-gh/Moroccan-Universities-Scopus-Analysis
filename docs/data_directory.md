# ğŸ“‚ Data Directory Documentation

## ğŸ¯ Overview
This document provides a comprehensive guide to the data directory structure and the data flow in the Moroccan Universities Scopus Analysis project. The data processing follows a sequential path through various stages, from raw data to the final star schema model.

## ğŸ“ Directory Structure

```
data/
â”œâ”€â”€ ğŸ“¥ raw/                      # Original source data
â”‚   â”œâ”€â”€ Universities-Affiliations/
â”‚   â”‚   â””â”€â”€ Moroccan-Affiliations.csv
â”‚   â”œâ”€â”€ scopus/              # Scopus export files
â”‚   â”œâ”€â”€ sjr/                 # Journal metrics data
â”‚   â””â”€â”€ ensupp/              # Additional data sources
â”œâ”€â”€ ğŸ”„ transformed/             # Cleaned and standardized data
â”œâ”€â”€ âœ¨ final/                   # Combined and validated data
â”œâ”€â”€ ğŸ“Š dimensions/              # Dimension tables
â””â”€â”€ ğŸ“‹ fact/                    # Fact tables
```

## ğŸ“¦ Data Flow Timeline

### 1. ğŸ“¥ Raw Data Stage (`/raw`)
- **Input Location**: `data/raw/`
- **Contents**:
  - `Universities-Affiliations/`: Moroccan universities and institutions data
    - `Moroccan-Affiliations.csv`: Master list of Moroccan institutions
  - `scopus/`: Raw Scopus publication exports
  - `sjr/`: Journal metrics and rankings
  - `ensupp/`: Supplementary data sources

#### ğŸ“ File Formats
- CSV files with original headers
- Potentially inconsistent naming conventions
- May contain special characters or multiple languages

### 2. ğŸ”„ Transformation Stage (`/transformed`)
- **Input**: Files from `/raw`
- **Output Location**: `data/transformed/`
- **Files**:
  - `affiliations.csv`: Standardized institution names
  - `clean_journal_23.csv`: Processed journal data
  - `transformed_2021.csv`: Cleaned 2021 publications
  - `transformed_2022.csv`: Cleaned 2022 publications
  - `transformed_2023.csv`: Cleaned 2023 publications

#### ğŸ”§ Transformations Applied
- Text normalization
- Language standardization
- Data cleaning and validation
- Format standardization

### 3. âœ¨ Integration Stage (`/final`)
- **Input**: Files from `/transformed`
- **Output Location**: `data/final/`
- **Purpose**: 
  - Combines transformed files
  - Resolves conflicts
  - Ensures data consistency
  - Prepares for star schema split

### 4. ğŸ“Š Star Schema Stage
#### ğŸ“‹ Dimension Tables (`/dimensions`)
- **Location**: `data/dimensions/`
- **Files**:
  - `affiliations.csv`: Institution dimension
  - `authors.csv`: Author dimension
  - `journals.csv`: Journal dimension

#### ğŸ“Š Fact Table (`/fact`)
- **Location**: `data/fact/`
- **Contents**: Publication facts with foreign keys to dimensions

## ğŸ“ˆ Data Quality Standards

### ğŸ“¥ Raw Data
- Original, unmodified files
- Preserved in original format
- Versioned if updates received

### ğŸ”„ Transformed Data
- Standardized formats
- Cleaned and validated
- Consistent naming conventions
- Mapped to standard values

### âœ¨ Final Data
- Fully validated
- Referential integrity maintained
- Ready for analytical queries

## ğŸ“ File Naming Conventions

### ğŸ“¥ Raw Files
- Original names preserved
- Date suffixes if multiple versions exist

### ğŸ”„ Transformed Files
- Format: `transformed_YYYY.csv`
- Clear indication of content type

### ğŸ“‹ Dimension and Fact Tables
- Named after the entity they represent
- Consistent with schema documentation

## ğŸ“ Data Retention Policy

1. ğŸ“¥ **Raw Data**
   - Retained indefinitely
   - Archived after processing

2. ğŸ”„ **Transformed Data**
   - Kept for validation
   - Can be regenerated from raw

3. âœ¨ **Final and Schema Data**
   - Active storage
   - Regular backups maintained

## ğŸ“Š Usage Guidelines

### ğŸ“‚ Accessing Raw Data
```bash
# Example path to raw Moroccan affiliations
data/raw/Universities-Affiliations/Moroccan-Affiliations.csv
```

### ğŸ”„ Working with Transformed Data
```bash
# Latest transformed publications
data/transformed/transformed_2023.csv
```

### ğŸ“Š Using Star Schema Tables
```bash
# Dimension tables
data/dimensions/[table_name].csv

# Fact table
data/fact/publications.csv
```

## ğŸ”„ Data Update Process

1. Place new raw data in appropriate `/raw` subdirectory
2. Run transformation scripts
3. Verify transformed output
4. Run integration process
5. Update star schema tables

## ğŸ” Monitoring and Maintenance

### ğŸ“Š Size Monitoring
- Regular checks on directory sizes
- Cleanup of temporary files
- Archival of old versions

### ğŸ“ˆ Data Quality Checks
- Validation after each transformation
- Integrity checks before loading
- Regular audits of final data

## ğŸ“š Related Documentation
- ETL Process: [etl_process.md](etl_process.md)
- Data Model: [data_model.md](data_model.md)
- Schema Documentation: See `models/schema.py`
